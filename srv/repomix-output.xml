This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
agent/bootstrap/http-trace.js
agent/helpers/logging.js
agent/index.js
agent/mcp-clients.js
claim-flat.cds
fe-annotations.cds
server.js
service.cds
service.js
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="agent/bootstrap/http-trace.js">
// Optional HTTP tracing for global fetch
// Enable with AGENT_HTTP_TRACE=1 or =true

const { redact, safeJson } = require('../helpers/logging');

function enableHttpTrace() {
  try {
    const on = process.env.AGENT_HTTP_TRACE === '1' || process.env.AGENT_HTTP_TRACE === 'true';
    if (!on) return;
    if (!globalThis.fetch) return; // Node <18 or no fetch polyfill
    if (globalThis.__agent_http_trace_enabled) return;
    globalThis.__agent_http_trace_enabled = true;

    const orig = globalThis.fetch;
    globalThis.fetch = async (input, init) => {
      const url = typeof input === 'string' ? input : input?.url;
      try {
        console.log('[HTTP][req]', {
          method: init?.method || 'GET',
          url,
          headers: redact(init?.headers),
          bodyPreview: safeJson(init?.body, 1000),
        });
      } catch {}
      const res = await orig(input, init);
      try {
        const clone = res.clone?.() || res; // some fetch impl may not support clone
        let body = '';
        try { body = await clone.text(); } catch {}
        const headersObj = {};
        try {
          if (res.headers && typeof res.headers.entries === 'function') {
            for (const [k, v] of res.headers.entries()) headersObj[k] = v;
          }
        } catch {}
        console.log('[HTTP][res]', {
          status: res.status,
          url: res.url,
          headers: headersObj,
          bodyPreview: body && body.length > 1000 ? body.slice(0, 1000) + ' …[truncated]' : body
        });
      } catch {}
      return res;
    };
  } catch {}
}

module.exports = { enableHttpTrace };
</file>

<file path="agent/helpers/logging.js">
// Logging helpers: redact sensitive info, safe JSON stringify, and unwrap nested errors

function redact(obj) {
  try {
    const clone = JSON.parse(JSON.stringify(obj || {}));
    const headers = clone?.headers || clone?.response?.headers;
    const findHeader = (k) => headers && Object.keys(headers).find((h) => String(h).toLowerCase() === k);
    const authKey = findHeader('authorization');
    if (authKey) headers[authKey] = '***';
    const cookieKey = findHeader('cookie');
    if (cookieKey) headers[cookieKey] = '***';
    if (clone?.access_token) clone.access_token = '***';
    if (clone?.token) clone.token = '***';
    if (clone?.apiKey) clone.apiKey = '***';
    return clone;
  } catch {
    return undefined;
  }
}

function safeJson(x, max = 4000) {
  try {
    const s = typeof x === 'string' ? x : JSON.stringify(x);
    return s.length > max ? s.slice(0, max) + ' …[truncated]' : s;
  } catch {
    try { return String(x); } catch { return '[unprintable]'; }
  }
}

function unwrapError(err, maxDepth = 5) {
  const chain = [];
  let cur = err;
  let depth = 0;
  while (cur && depth < maxDepth) {
    chain.push({
      name: cur?.name,
      message: cur?.message,
      code: cur?.code ?? cur?.status ?? cur?.statusCode,
      responseStatus: cur?.response?.status ?? cur?.response?.statusCode,
      responseData: cur?.response?.data ?? cur?.response?.body,
      responseHeaders: redact(cur?.response?.headers),
      url: cur?.config?.url ?? cur?.options?.url,
      method: cur?.config?.method ?? cur?.options?.method,
      params: cur?.config?.params,
      requestData: cur?.config?.data,
    });
    cur = cur?.cause;
    depth += 1;
  }
  return chain;
}

module.exports = { redact, safeJson, unwrapError };
</file>

<file path="agent/index.js">
// New Agent implementation: LangGraph React-Agent + MCP tools (M365 only)
// CommonJS with dynamic imports for ESM-only packages

let agentExecutor = null;
let mcpClients = null;
let agentInfo = { toolNames: [], modelName: '' };
const { unwrapError, safeJson } = require('./helpers/logging');
const { enableHttpTrace } = require('./bootstrap/http-trace');

function sseWrite(res, data) {
  if (data == null) return;
  const s = String(data);
  const lines = s.split(/\r?\n/);
  let lastBlank = false;
  for (const line of lines) {
    const isBlank = line.length === 0;
    if (isBlank && lastBlank) continue; // collapse multiple blank lines into one
    res.write(`data: ${line}\n`);
    lastBlank = isBlank;
  }
  res.write(`\n`);
}
// Emit smaller SSE chunks to improve incremental rendering in the UI
function sseWriteChunked(res, text) {
  const enable = process.env.AGENT_SSE_SPLIT !== '0';
  const chunkSize = Math.max(16, Number(process.env.AGENT_SSE_CHUNK_SIZE || 80));
  if (!enable) return sseWrite(res, text);
  const str = String(text || '');
  if (!str) return;
  const lines = str.split(/\r?\n/);
  for (const line of lines) {
    if (line.length <= chunkSize) { sseWrite(res, line); continue; }
    let i = 0;
    const n = line.length;
    while (i < n) {
      let end = Math.min(i + chunkSize, n);
      // try to break at a pleasant boundary within the window
      let j = line.lastIndexOf('.', end);
      if (j < i) j = line.lastIndexOf('!', end);
      if (j < i) j = line.lastIndexOf('?', end);
      if (j < i) j = line.lastIndexOf(' ', end);
      if (j < i) j = end;
      const piece = line.slice(i, j).trimStart();
      if (piece) sseWrite(res, piece);
      i = (j === i ? i + chunkSize : j);
    }
    // send an explicit newline between long logical lines to help UI paragraphing
    sseWrite(res, '');
  }
}
function sseJson(res, obj) { sseWrite(res, JSON.stringify(obj)); }
function sseEnd(res) { res.write('event: end\n'); res.write('data: [DONE]\n\n'); res.end(); }
function sseError(res, obj) {
  try {
    res.write('event: error\n');
    res.write(`data: ${JSON.stringify(obj)}\n\n`);
  } catch (_) {}
}

async function initAgent() {
  if (agentExecutor) return agentExecutor;

  // Optional HTTP tracing for fetch
  try { enableHttpTrace(); } catch (_) {}

  const { initAllMCPClients } = require('./mcp-clients');
  const { loadMcpTools } = await import('@langchain/mcp-adapters');
  const { createReactAgent } = await import('@langchain/langgraph/prebuilt');
  const { MemorySaver } = await import('@langchain/langgraph-checkpoint');
  const { AzureOpenAiChatClient } = await import('@sap-ai-sdk/langchain');

  // 1) MCP Clients (only M365 for now)
  mcpClients = await initAllMCPClients();

  // 2) Load tools from M365 MCP (all available)
  const allTools = [];
  if (mcpClients.m365) {
    try {
      const toolsResp = await mcpClients.m365.listTools();
      const names = (toolsResp.tools || []).map(t => t.name).join(',');
      if (names) {
        const m365 = await loadMcpTools(names, mcpClients.m365);
        allTools.push(...m365);
      }
    } catch (e) {
      // If listing tools fails, continue without tools
    }
  }

  // 3) LLM + in-memory checkpointing
  const llm = new AzureOpenAiChatClient(
    {
      modelName: process.env.AI_MODEL_NAME || 'gpt-4.1',
      temperature: Number(process.env.AI_TEMPERATURE || 1),
      maxCompletionTokens: Number(500),
    },
    { destinationName: process.env.AI_DESTINATION_NAME || 'aicore-destination' }
  );
  const checkpointer = new MemorySaver();

  // Log effective LLM config + optional diag ping
  try {
    const kw = (llm && llm.lc_serializable && llm.lc_serializable.kwargs) || {};
    console.log('[AGENT][llm_config]', {
      model: kw.model || kw.modelName,
      temperature: kw.temperature,
      maxTokens: kw.maxTokens,
      maxCompletionTokens: kw.maxCompletionTokens,
      topP: kw.topP,
      frequencyPenalty: kw.frequencyPenalty,
    });
  } catch (_) {}
  if (process.env.AGENT_DIAG === '1' || process.env.AGENT_DIAG === 'true') {
    try {
      const r = await llm.invoke([
        { role: 'system', content: 'You are a helpful assistant.' },
        { role: 'user', content: 'ping' },
      ], { maxCompletionTokens: 8 });
      try {
        const out = typeof r === 'string' ? r : (r && r.content ? r.content : r);
        console.log('[AGENT][diag_llm_ok]', typeof out === 'string' ? out.slice(0, 120) : out);
      } catch (_) {}
    } catch (e) {
      try {
        const chain = unwrapError(e);
        console.error('[AGENT][diag_llm_err]', safeJson(chain, 4000));
      } catch (_) {}
      throw e; // fail fast in diag mode for visibility
    }
  }

  // 4) Create agent
  agentExecutor = createReactAgent({
    llm,
    tools: allTools,
    checkpointSaver: checkpointer,
  });

  // capture agent info for diagnostics
  try {
    agentInfo.toolNames = (allTools || []).map(t => t?.name || 'unknown');
    agentInfo.modelName = llm?.lc_serializable?.kwargs?.model || process.env.AI_MODEL_NAME || 'gpt-4.1';
    console.log('[AGENT][init]', {
      model: agentInfo.modelName,
      tools: agentInfo.toolNames,
      m365Enabled: !!mcpClients.m365,
    });
  } catch (_) {}
  return agentExecutor;
}

async function runAgentStreaming({ prompt, threadId, res }) {
  if (!prompt || !String(prompt).trim()) {
    res.statusCode = 400;
    sseJson(res, { error: 'Prompt is required' });
    return sseEnd(res);
  }
  const executor = await initAgent();

  const { randomUUID } = require('crypto');
  const reqId = (() => { try { return randomUUID(); } catch (_) { return 'req-' + Date.now(); } })();
  const traceEnabled = process.env.AGENT_TRACE === '1' || process.env.AGENT_TRACE === 'true';
  const trace = traceEnabled ? [] : null;
  const startedAt = Date.now();
  let sentChars = 0;
  let sentPreview = '';
  const logOutput = process.env.AGENT_LOG_OUTPUT !== '0';
  const logSteps = process.env.AGENT_LOG_STEPS !== '0';
  let step = 0;                // ReAct round number
  let awaitingTool = false;    // currently waiting for tool output
  let phase = 'init';          // 'init' | 'reason' | 'tool' | 'observation'
  try {
    console.log('[AGENT][start]', {
      reqId,
      threadId: String(threadId || 'default'),
      model: agentInfo.modelName || (process.env.AI_MODEL_NAME || 'gpt-4.1'),
      tools: agentInfo.toolNames,
      promptPreview: String(prompt).slice(0, 200)
    });
    if (traceEnabled) trace.push({ t: Date.now(), type: 'start', reqId, threadId: String(threadId || 'default'), prompt: String(prompt) });
  } catch (_) {}

  const systemMessage = {
    role: 'system',
    content:
      'You are a helpful assistant. You can use MCP tools (Microsoft 365 etc.). ' +
      'Explain briefly what you are doing when invoking tools.',
  };
  const userMessage = { role: 'user', content: String(prompt) };

  try {
    // Stream agent events as SSE
    const callbacks = [{
      handleLLMStart: (_llm, prompts) => {
        try {
          const first = Array.isArray(prompts) && prompts.length ? prompts[0] : undefined;
          const preview = first ? (typeof first === 'string' ? first : JSON.stringify(first)).slice(0, 400) : undefined;
          console.log('[AGENT][llm_start]', { reqId, prompts: Array.isArray(prompts) ? prompts.length : undefined, preview });
          if (traceEnabled) trace.push({ t: Date.now(), type: 'llm_start', preview });
        } catch (_) {}
      },
      handleLLMEnd: () => {
        try { console.log('[AGENT][llm_end]', { reqId }); if (traceEnabled) trace.push({ t: Date.now(), type: 'llm_end' }); } catch (_) {}
      },
      handleLLMError: (err) => {
        try { console.error('[AGENT][llm_error]', { reqId, message: err && err.message, name: err && err.name }); if (traceEnabled) trace.push({ t: Date.now(), type: 'llm_error', message: err && err.message }); } catch (_) {}
      },
      handleToolStart: (tool, input) => {
        try {
          const prev = typeof input === 'string' ? input : JSON.stringify(input || '');
          console.log('[AGENT][cb_tool_start]', { reqId, tool, inputPreview: prev.slice(0, 200) });
          if (traceEnabled) trace.push({ t: Date.now(), type: 'tool_start', tool, inputPreview: prev.slice(0, 400) });
        } catch (_) {}
      },
      handleToolEnd: (output) => {
        try {
          const prev = typeof output === 'string' ? output : JSON.stringify(output || '');
          console.log('[AGENT][cb_tool_end]', { reqId, outputPreview: prev.slice(0, 200) });
          if (traceEnabled) trace.push({ t: Date.now(), type: 'tool_end', outputPreview: prev.slice(0, 400) });
        } catch (_) {}
      },
      handleToolError: (err) => {
        try { console.error('[AGENT][cb_tool_error]', { reqId, message: err && err.message, name: err && err.name }); if (traceEnabled) trace.push({ t: Date.now(), type: 'tool_error', message: err && err.message }); } catch (_) {}
      }
    }];

    const stream = await executor.stream(
      { messages: [systemMessage, userMessage] },
      {
        recursionLimit: Number(process.env.AGENT_RECURSION_LIMIT || 100),
        configurable: { thread_id: String(threadId || 'default') },
        callbacks
      }
    );

    for await (const chunk of stream) {
      // Agent text tokens
      if (chunk && chunk.agent && Array.isArray(chunk.agent.messages)) {
        const msg = chunk.agent.messages[chunk.agent.messages.length - 1];
        if (msg && msg.content) {
          const text = typeof msg.content === 'string'
            ? msg.content
            : Array.isArray(msg.content)
              ? msg.content.map(p => (typeof p === 'string' ? p : p?.text || '')).join('')
              : '';
          if (text) {
            if (logOutput) {
              try {
                sentChars += text.length;
                if (sentPreview.length < 800) {
                  const needed = 800 - sentPreview.length;
                  sentPreview += text.slice(0, needed);
                }
                // per-chunk live log (short preview)
                const live = text.length > 160 ? text.slice(0, 160) + ' ... ' : text;
                console.log('[AGENT][send]', live);
              } catch (_) {}
            }
            sseWriteChunked(res, text);
            // Step logging: reasoning (no tool call in this message)
            try {
              const msgHasToolCalls = Array.isArray(msg.tool_calls) && msg.tool_calls.length > 0;
              if (logSteps && !msgHasToolCalls && !awaitingTool) {
                if (phase !== 'reason') {
                  step += 1;
                  console.log('[AGENT][step]', { step, action: 'reason', preview: text.slice(0, 200) });
                }
                phase = 'reason';
              }
            } catch (_) {}
          }
          if (Array.isArray(msg.tool_calls) && msg.tool_calls.length > 0) {
            const call = msg.tool_calls[0];
            try { console.log('[AGENT][tool_start]', { tool: call.name, args: call.args || {} }); } catch (_) {}
            if (logSteps) {
              try { if (phase !== 'tool') { /* keep same step for this round */ } console.log('[AGENT][step]', { step: Math.max(step, 1), action: 'tool_call', tool: call.name }); } catch (_) {}
            }
            awaitingTool = true;
            phase = 'tool';
          }
        }
      }

      // Tool outputs
      if (chunk && chunk.tools && Array.isArray(chunk.tools.messages) && chunk.tools.messages.length > 0) {
        const toolMsg = chunk.tools.messages[0];
        const toolText = typeof toolMsg?.content === 'string'
          ? toolMsg.content
          : Array.isArray(toolMsg?.content)
            ? toolMsg.content.map(p => (typeof p === 'string' ? p : p?.text || '')).join('')
            : '';
        if (toolText) {
          const preview = String(toolText).slice(0, 500);
          try { console.log('[AGENT][tool_output]', preview + (toolText.length > 500 ? ' ...[truncated]' : '')); } catch (_) {}
          if (logSteps) {
            try { if (step === 0) step = 1; console.log('[AGENT][step]', { step, action: 'observation', preview: String(toolText).slice(0, 200) }); } catch (_) {}
          }
        }
        awaitingTool = false;
        phase = 'observation';
      }
    }

    const tookMs = Date.now() - startedAt;
    try {
      console.log('[AGENT][end]', { threadId: String(threadId || 'default'), ms: tookMs });
      if (logOutput) {
        const prev = sentPreview.replace(/\s+/g, ' ').slice(0, 400);
        console.log('[AGENT][response_end]', { chars: sentChars, preview: prev + (sentChars > prev.length ? ' …' : '') });
      }
    } catch (_) {}
    sseEnd(res);
  } catch (e) {
    // Enhanced error logging with deep unwrap and sanitized SSE response
    try {
      const chain = unwrapError(e);

      // concise console summary
      try {
        const summary = chain.map((c, i) => ({
          i,
          name: c.name,
          code: c.code,
          responseStatus: c.responseStatus,
          message: (c?.message || '').slice(0, 500),
        }));
        console.error('[AGENT][error]', { reqId, summary });
      } catch (_) {}

      if (traceEnabled) {
        try { console.error('[AGENT][error_detail]', safeJson(chain, 8000)); } catch (_) {}
      }

      // extract Azure/AICore error if present
      const primary = chain.find(c => c.responseData) || chain[0] || {};
      let azureError;
      try {
        const d = typeof primary.responseData === 'string'
          ? JSON.parse(primary.responseData)
          : primary.responseData;
        const err = (d && d.error) || d || {};
        azureError = {
          code: err.code,
          message: err.message,
          inner: err.innererror || err.details || undefined,
        };
      } catch (_) {}

      const clientErr = {
        reqId,
        status: primary.responseStatus || primary.code || 500,
        code: (azureError && azureError.code) || (chain[0] && chain[0].code) || 'ERR',
        message: (azureError && azureError.message) || (chain[0] && chain[0].message) || 'Agent failed',
        inner: azureError && azureError.inner,
      };
      sseError(res, clientErr);
    } catch (_) {
      try { sseError(res, { message: 'Agent failed' }); } catch (_) {}
    }
    try { sseEnd(res); } catch (_) {}
  }
}

module.exports = { runAgentStreaming };
</file>

<file path="agent/mcp-clients.js">
// Minimal MCP client bootstrap: only M365 (stdio) for now
// CommonJS file using dynamic ESM imports where needed

const process = require('process');

function parseCommandLine(cmd) {
  const tokens = [];
  let cur = '';
  let q = null;
  for (let i = 0; i < cmd.length; i++) {
    const ch = cmd[i];
    if (q) {
      if (ch === q) q = null; else cur += ch;
    } else if (ch === '"' || ch === "'") {
      q = ch;
    } else if (ch === ' ') {
      if (cur) { tokens.push(cur); cur = ''; }
    } else {
      cur += ch;
    }
  }
  if (cur) tokens.push(cur);
  const command = tokens.shift();
  return { command, args: tokens };
}

async function startMcpClient(name, command, args, env) {
  const { Client } = await import('@modelcontextprotocol/sdk/client/index.js');
  const { StdioClientTransport } = await import('@modelcontextprotocol/sdk/client/stdio.js');
  const transport = new StdioClientTransport({ command, args, env: { ...process.env, ...env } });
  const client = new Client({ name: `mcp-${name}`, version: '0.1.0' }, {});
  await client.connect(transport);
  return { client, transport };
}

async function initAllMCPClients() {
  const clients = {};

  // Only enable M365 MCP via env: MCP_M365_CMD e.g. "npx m365-mcp-server"
  if (process.env.MCP_M365_CMD) {
    try {
      const { command, args } = parseCommandLine(process.env.MCP_M365_CMD);
      if (!command) throw new Error('MCP_M365_CMD ist leer/ungültig');
      const { client } = await startMcpClient('m365', command, args, {});
      clients.m365 = client;
    } catch (e) {
      console.warn('[MCP] M365 start/connect failed:', e && e.message ? e.message : String(e));
    }
  }

  return clients;
}

async function closeMCPClients(clients = {}) {
  const all = Object.values(clients);
  await Promise.all(all.map(async (c) => { try { await c.close(); } catch (_) {} }));
}

module.exports = { initAllMCPClients, closeMCPClients };
</file>

<file path="claim-flat.cds">
using { sap.kfz as kfz } from '../db/schema';

entity ClaimFlat as select from kfz.Claim {
  *,
  policy.policyNumber as policyNumber,
  vehicle.plate       as plate
};
</file>

<file path="fe-annotations.cds">
using KfzService as service from './service';

annotate service.Claim with @(
  UI.HeaderInfo : {
    TypeName       : 'Schaden',
    TypeNamePlural : 'Schaeden',
    Title          : { Value : claimNumber },
    Description    : { Value : status }
  },

  UI.SelectionFields : [
    claimNumber, status, severity, lossDate
  ],

  UI.LineItem : [
    { $Type : 'UI.DataField', Value : claimNumber,            Label : 'Claim',        ![@UI.Importance] : #High },
    { $Type : 'UI.DataField', Value : policy.policyNumber,    Label : 'Police',       ![@UI.Importance] : #High },
    { $Type : 'UI.DataField', Value : vehicle.plate,          Label : 'Kennzeichen',  ![@UI.Importance] : #High },
    { $Type : 'UI.DataField', Value : lossDate,               Label : 'Schadendatum', ![@UI.Importance] : #High },
    { $Type : 'UI.DataField', Value : status,                 Label : 'Status',       ![@UI.Importance] : #High },
    { $Type : 'UI.DataField', Value : severity,               Label : 'Schadenschwere' },
    { $Type : 'UI.DataField', Value : reportedDate,           Label : 'Meldedatum' }
  ],

  UI.Facets : [
    {
      $Type : 'UI.ReferenceFacet',
      Label : 'Allgemeine Informationen',
      Target: '@UI.FieldGroup#General'
    },
    {
      $Type : 'UI.ReferenceFacet',
      Label : 'Beschreibung',
      Target: '@UI.FieldGroup#Description'
    },
    {
      $Type : 'UI.ReferenceFacet',
      Label : 'E-Mails',
      Target: 'emails/@UI.LineItem'
    },
    {
      $Type : 'UI.ReferenceFacet',
      Label : 'Dokumente',
      Target: 'documents/@UI.LineItem'
    },
    {
      $Type : 'UI.ReferenceFacet',
      Label : 'Aufgaben',
      Target: 'tasks/@UI.LineItem'
    }
  ],

  UI.FieldGroup #General : {
    Data : [
      { Value : claimNumber,          Label : 'Claim' },
      { Value : status,               Label : 'Status' },
      { Value : severity,             Label : 'Schadenschwere' },
      { Value : lossDate,             Label : 'Schadendatum' },
      { Value : reportedDate,         Label : 'Meldedatum' },
      { Value : policy.policyNumber,  Label : 'Police' },
      { Value : vehicle.plate,        Label : 'Kennzeichen' },
      { Value : reserveAmount,        Label : 'Reserve' }
    ]
  },

  UI.FieldGroup #Description : {
    Data : [
      { Value : description, Label : 'Beschreibung' }
    ]
  }
);

annotate service.Claim with {
  description   @title : 'Beschreibung'            @UI.MultiLineText;
  claimNumber   @title : 'Claim';
  status        @title : 'Status';
  severity      @title : 'Schadenschwere';
  lossDate      @title : 'Schadendatum';
  reportedDate  @title : 'Meldedatum';
  reserveAmount @title : 'Reserve';
};

annotate service.Claim with @(
  Capabilities.InsertRestrictions  : { Insertable : true },
  Capabilities.UpdateRestrictions  : { Updatable  : true },
  Capabilities.DeleteRestrictions  : { Deletable  : true }
);

annotate service.Claim with {
  policy @Common.ValueList : {
    $Type          : 'Common.ValueListType',
    CollectionPath : 'Policy',
    Parameters     : [
      { $Type : 'Common.ValueListParameterInOut',  LocalDataProperty : policy_ID,  ValueListProperty : 'ID' },
      { $Type : 'Common.ValueListParameterDisplayOnly', ValueListProperty : 'policyNumber' }
    ]
  };
  vehicle @Common.ValueList : {
    $Type          : 'Common.ValueListType',
    CollectionPath : 'Vehicle',
    Parameters     : [
      { $Type : 'Common.ValueListParameterInOut',  LocalDataProperty : vehicle_ID, ValueListProperty : 'ID' },
      { $Type : 'Common.ValueListParameterDisplayOnly', ValueListProperty : 'plate' }
    ]
  };
};

annotate service.Email with @(
  UI.LineItem : [
    { $Type : 'UI.DataField', Value : subject,       Label : 'Betreff' },
    { $Type : 'UI.DataField', Value : fromAddress,   Label : 'Von' },
    { $Type : 'UI.DataField', Value : receivedAt,    Label : 'Empfangen am' },
    { $Type : 'UI.DataField', Value : hasAttachments,Label : 'Anhänge' }
  ]
);

annotate service.Email with @(
  Capabilities.InsertRestrictions  : { Insertable : true },
  Capabilities.UpdateRestrictions  : { Updatable  : true },
  Capabilities.DeleteRestrictions  : { Deletable  : true }
);

annotate service.Document with @(
  UI.LineItem : [
    { $Type : 'UI.DataField', Value : fileName,   Label : 'Datei' },
    { $Type : 'UI.DataField', Value : mimeType,   Label : 'Typ' },
    { $Type : 'UI.DataField', Value : source,     Label : 'Quelle' }
  ]
);

annotate service.Document with @(
  Capabilities.InsertRestrictions  : { Insertable : true },
  Capabilities.UpdateRestrictions  : { Updatable  : true },
  Capabilities.DeleteRestrictions  : { Deletable  : true }
);

annotate service.Task with @(
  UI.LineItem : [
    { $Type : 'UI.DataField', Value : type,     Label : 'Typ' },
    { $Type : 'UI.DataField', Value : status,   Label : 'Status' },
    { $Type : 'UI.DataField', Value : dueDate,  Label : 'Fällig am' },
    { $Type : 'UI.DataField', Value : assignee, Label : 'Bearbeiter' }
  ]
);

annotate service.Task with @(
  Capabilities.InsertRestrictions  : { Insertable : true },
  Capabilities.UpdateRestrictions  : { Updatable  : true },
  Capabilities.DeleteRestrictions  : { Deletable  : true }
);
</file>

<file path="server.js">
const cds = require('@sap/cds');

async function streamGenAI(prompt, res, opts = {}) {
  function sseWrite(res, data) {
    if (data == null) return;
    const s = String(data);
    const lines = s.split(/\r?\n/);
    for (const line of lines) {
      res.write(`data: ${line}\n`);
    }
    res.write(`\n`);
  }
  const { AzureOpenAiChatClient } = await import('@sap-ai-sdk/langchain');
  const destinationName = process.env.AI_DESTINATION_NAME || 'aicore-destination';
  const modelName = process.env.AI_MODEL_NAME || 'gpt-4.1';

  const client = new AzureOpenAiChatClient({ modelName, temperature: 0.3 }, { destinationName });

  const forceFallback = !!opts.forceFallback;
  try {
    if (forceFallback) throw new Error('forced-fallback');
    const stream = await client.stream([
      { role: 'user', content: String(prompt || '') }
    ]);

    for await (const chunk of stream) {
      const piece = typeof chunk.content === 'string'
        ? chunk.content
        : Array.isArray(chunk.content)
          ? chunk.content.map(p => (typeof p === 'string' ? p : p?.text || '')).join('')
          : '';
      if (piece) sseWrite(res, piece);
    }
  } catch (e) {
    const result = await client.invoke([
      { role: 'user', content: String(prompt || '') }
    ]);
    const content = typeof result.content === 'string'
      ? result.content
      : Array.isArray(result.content)
        ? result.content.map(p => (typeof p === 'string' ? p : p?.text || '')).join('')
        : '';
    const text = String(content || '');
    const chunkSize = 64;
    for (let i = 0; i < text.length; i += chunkSize) {
      const piece = text.slice(i, i + chunkSize);
      if (piece) sseWrite(res, piece);
      await new Promise(r => setTimeout(r, 10));
    }
  }
  res.write(`event: end\n`);
  res.write(`data: [DONE]\n\n`);
  res.end();
}

cds.on('bootstrap', (app) => {
  // Server-Sent Events endpoint for streaming chat responses
  app.post('/ai/stream', expressJson(), async (req, res) => {
    try {
      const prompt = (req.body && req.body.prompt) || '';
      res.status(200);
      res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');
      res.setHeader('Cache-Control', 'no-cache, no-transform');
      res.setHeader('Connection', 'keep-alive');
      res.setHeader('X-Accel-Buffering', 'no');
      res.flushHeaders && res.flushHeaders();
      const forceFallback = req.headers['x-use-fallback'] === '1' || req.query.fallback === '1';
      await streamGenAI(prompt, res, { forceFallback });
    } catch (e) {
      try {
        res.write(`event: error\n`);
        res.write(`data: ${JSON.stringify({ message: e && e.message ? e.message : String(e) })}\n\n`);
        res.end();
      } catch (_) { /* ignore */ }
    }
  });
  // Agent endpoint: LangGraph + MCP tools (no fallback)
  app.post('/ai/agent/stream', expressJson(), async (req, res) => {
    try {
      const { runAgentStreaming } = require('./agent');
      const prompt = (req.body && req.body.prompt) || '';
      const threadId = (req.body && req.body.threadId) || undefined;
      res.status(200);
      res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');
      res.setHeader('Cache-Control', 'no-cache, no-transform');
      res.setHeader('Connection', 'keep-alive');
      res.setHeader('X-Accel-Buffering', 'no');
      res.flushHeaders && res.flushHeaders();
      await runAgentStreaming({ prompt, threadId, res });
    } catch (e) {
      try {
        res.write(`event: error\n`);
        res.write(`data: ${JSON.stringify({ message: e && e.message ? e.message : String(e) })}\n\n`);
        res.end();
      } catch (_) { /* ignore */ }
    }
  });
});

function expressJson() {
  const express = require('express');
  return express.json();
}

module.exports = {};
</file>

<file path="service.cds">
using { sap.kfz as kfz } from '../db/schema';

service KfzService @(path:'/service/kfz') {
  entity Insured   as projection on kfz.Insured;
  entity Policy    as projection on kfz.Policy;
  entity Vehicle   as projection on kfz.Vehicle;
  @odata.draft.enabled
  entity Claim     as projection on kfz.Claim;
  entity Email     as projection on kfz.Email;
  entity Document  as projection on kfz.Document;
  entity Task      as projection on kfz.Task;

  type ChatResponse { response : LargeString; }
  action callLLM(prompt : String) returns ChatResponse;
}
</file>

<file path="service.js">
// .env loading optional; CAP usually injects env via process environment

const escapeHtml = (str = '') => String(str)
  .replace(/&/g, '&amp;')
  .replace(/</g, '&lt;')
  .replace(/>/g, '&gt;')
  .replace(/\"/g, '&quot;')
  .replace(/'/g, '&#39;');

function buildHtmlResponse(title, bodyHtml) {
  return [
    '<section style="font-family:Arial,Helvetica,sans-serif">',
    `<h3>${escapeHtml(title)}</h3>`,
    bodyHtml,
    '</section>'
  ].join('\n');
}

async function callSAPGenAIHubViaLangChain(prompt) {
  const { AzureOpenAiChatClient } = await import('@sap-ai-sdk/langchain');
  const destinationName = process.env.AI_DESTINATION_NAME || 'aicore-destination';
  const modelName = process.env.AI_MODEL_NAME || 'gpt-4.1';

  const chat = new AzureOpenAiChatClient(
    { modelName, temperature: 0.3 },
    { destinationName }
  );

  const res = await chat.invoke(String(prompt || ''));
  const content = typeof res.content === 'string'
    ? res.content
    : Array.isArray(res.content)
      ? res.content.map(part => (typeof part === 'string' ? part : part?.text || '')).join('')
      : '';
  return String(content || '').trim();
}

module.exports = async (srv) => {
  srv.on('callLLM', async (req) => {
    const { prompt } = req.data || {};

    try {
      const answer = await callSAPGenAIHubViaLangChain(prompt);
      const safeAnswer = escapeHtml(answer);
      const html = buildHtmlResponse('AI Antwort (GPT-4.1 via SAP GenAI LangChain)', `<pre style=\"white-space:pre-wrap\">${safeAnswer}</pre>`);
      return { response: html };
    } catch (e) {
      const reason = e && e.message ? e.message : String(e);
      const html = buildHtmlResponse('AI Fehler', [
        '<p>Die Anfrage an SAP GenAI (LangChain, AzureOpenAiChatClient) ist fehlgeschlagen.</p>',
        `<p><b>Grund:</b> ${escapeHtml(reason)}</p>`,
        '<p>Bitte prüfen:</p>',
        '<ul>',
        '<li>Destination \"aicore-destination\" existiert im BTP Destination Service.</li>',
        '<li>Lokale Bindings vorhanden (cds bind destination/aicore) für Hybrid.</li>',
        '<li>Ausgehende Netzwerkverbindung ist erlaubt.</li>',
        '</ul>'
      ].join(''));
      return { response: html };
    }
  });
};
</file>

</files>
