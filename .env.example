# Example configuration for the CLI streaming bridge
# Copy to .env and adjust as needed.

# Which CLI command should be started for prompts?
LLM_CMD=powershell.exe
# Arguments for the CLI. Use {PROMPT} placeholder when LLM_INPUT_MODE=arg.
LLM_ARGS=-NoLogo -NoProfile -ExecutionPolicy Bypass -Command {PROMPT}
# How to send the prompt: "arg" replaces {PROMPT} in LLM_ARGS, "stdin" writes to STDIN.
LLM_INPUT_MODE=arg
# Encoding for stdout/stderr (utf8 is usually fine on Windows).
LLM_ENCODING=utf8
# Language tag for the Markdown code fence (controls frontend styling).
CLI_FENCE_LANG=powershell
# Optional debug logging of exit codes.
LLM_LOG=0
# Optional timeout (ms) before terminating long-running CLI processes.
CLI_TIMEOUT_MS=10000
